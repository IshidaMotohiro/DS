# 第５週その１：データの探索{#exploratory}

```{r exploratory, echo=FALSE}
library(tidyverse)
```


## データ探索とは{#explore2}

データの特徴を知るための指標となるのは平均値だけではない。前章では、中央値や最頻値について紹介した。またデータは分布で考えることが重要であることも指摘した。分布を検討するにはデータをグラフで表現する（可視化する）ことが有益である。
前節では、データにポアソン分布を仮定したが、時には仮定した分布ではありえないような大きな値（あるいは小さな値）が紛れ込んでいる場合がある。こうした値を**外れ値**と呼ぶが、こうした異常な点の存在を認識するにも可視化は有効である。データの分析を始める前に、まず可視化によってデータの特徴を捉えることは非常に重要である。
そこで、ここではデータサイエンスでよく利用される可視化手法について解説しよう。
あわせて数値的な指標についても付記する。


## 分布の可視化{#visualize}

前章では、データに分布を当てはめることを説明した。また分布の例として、ポアソン分布と正規分布を紹介した。
多くの場合、データについての予備知識に基づいて確率分布を仮定することになるだろう。
例えば、生物の体長や、機械的に生産される工業製品の寸法は、正規分布を仮定するのが一般的である。

特定のデータについて、その確率分布が確定できない場合は、似ているようなデータセットを想定して、後者で使われる確率分布を援用することも考えられる。
例えば、ある地方大学のキャンパス奥に立地する校舎の前に遊歩道があるとする。休日にこの遊歩道を通行する教職員ないし学生を（暇な話だが）一日観測したデータセットがあるとしよう（この場合、データセットとは、例えば100日分の観測値が揃っているという意味である）。

```{r walk}
set.seed(123)
x <- rpois(100, lambda = 2)
X <- table(x)
knitr::kable(t(X))
```

この表は分割表と呼ばれる。表の上（表頭）の0の列は、遊歩道に一人も観測されたなかった日が 13日あったことを示している。回数のデータであり、また生起数も少ない（あまり人が来ない）ようなので、ポアソン分布を仮定することが思いつく。それが妥当かどうかを、まずは確認しておきたい。このような場合、データを棒グラフ（バーチャート）で表して、その形状を確認するのが1つの手段である。

```{r pois_ggpot2}
tibble(X = x) %>% ggplot(aes(X)) +
  geom_histogram(binwidth=1, colour = "black", fill = "white")
```

さて、データの平均値を求めてみよう。

```{r mean_pois}
mean(x)
```

この標本平均値をパラメータとするポアソン分布で、0 から 6 までの理論的な頻度を求め、先程のバープロットに重ねてみよう


```{r pois_density}
tibble(Y = table(x), X= 0:6) %>% ggplot(aes(X, Y)) +
  geom_bar(stat="identity", colour = "black", fill = "white") +
  geom_point(aes(y=dpois(X, 2)*100), colour="red", size= 5)
```

丸い点が、パラメータ2.0のポアソン分布の場合に想定される回数である。
おおむね各バーの上の辺に近い位置にあることが確認できる。
よって、休日の遊歩道を散策する人の人数は、パラメータ2.0のポアソン分布に従うと判断できそうである。ただし、グラフの見た目の印象で判断するのでは信用できないというのであれば、後述する検定（適合度の検定）という方法を使って、実際の観測値と、その理論値が近いかどうかを判断する方法もある。検定を使えば、グラフの印象ではなく、数値（具体的には確率）に基づく判断が可能になる。

### 箱ひげ図{#boxplot}


例えば、ある高校で3年生男子約100名の身長を測ったデータがあるとする。
一般に、3年生男子高校生の身長の平均値約170センチである。これは文部科学省の「学校保健統計調査」で確認できる。少し脱線するが、こうした政府統計は、e-stat (https://www.e-stat.go.jp/) というポータルで誰でも入手することができる。サイトで「学校保健統計調査」を検索すると、過去のデータのリストが表示される。平成30年度全国版で「年齢別　都市階級別　設置者別　身長・体重の平均値及び標準偏差」を参照されたい。




```{r height, echo=FALSE}
set.seed(123)
x <- round(rnorm(100, mean = 170, sd = 5.78), 1)
x[91] <- 116
x[92] <- 109
x[93] <- 117
x[94] <- 108
x[95] <- 116
x[96] <- 108
x[97] <- 107
x[98] <- 109
x[99] <- 106
x[100] <- 107

# x[91:100] <- x[91:100] -  round(rnorm(10, mean = 30, sd = 2),0)
# mean(x)
```

さて、この高校のデータで平均値を探ったところ、平均値は164センチであった。
全国平均値よりもかなり低い。この高校の男子生徒の間には、なにか健康上の問題があるんだろうか？

まずは、データの分布を確認しておこう。この場合、よく使われるグラフに箱ひげ図がある。


```{r boxplot}
df <- tibble(身長 = x,x = "A")
p <- df %>% ggplot(aes(x = x, y=身長)) +
  geom_boxplot(outlier.shape = NA)
p + geom_jitter() 
```

すこし分かりにくいグラフかもしれない。まず、黒いドットはそれぞれ身長の値を表す。つまり、このグラフには高校生100人分のドットが描かれている。点のほとんどは白い箱に重なるように散らばっているが、いくつかの点が箱の下の方に確認できるだろう。縦軸の目盛りと対応させると、身長120センチ以下の生徒が複数人いることになるが、これは正しい記録であろうか？例えば、170 センチを誤って 107 センチと記録してしまったのではないだろうか。

ちなみに、箱ひげ図という名前は、グラフに横長の箱が描かれ、その上下に線が伸びていることによる。
箱の中心にはやや太い黒線が描かれているが、これは中央値に対応する。
そして箱の底は第1四分位数、箱の蓋は第3四分位数に対応する。
**第1四分位数**とは、データを大きさで並び替えた場合、小さい方から1/4個のデータ（あるいはその平均）の値に相当する、
**第3四分位数**は3/4個目となる。中央値は第2四分位数とも言える。
第1四分位数から第3四分位数までの範囲を**四分位範囲**とも言う。


```{r iqr}
quantile(x)
```

中央値を表す線が、箱の上辺ないし下辺に寄っている場合、その標本データには偏りがあることが示唆されている。ここで偏りとは、例えばデータに飛び抜けて大きな（あるいは小さな）観測値があるため、平均値を中心に左右対称にデータが散らばっておらず、平均値より小さな（あるいは大きな）領域にデータが集中しているような状態を言う。

先に、データサイエンスにおいては、データに正規分布を仮定することで、分析の手順が簡易化されると指摘した。正規分布の特徴は、平均値を中心にデータが左右対称に散っていることである。ちなみに、正規分布にあっては平均値と中央値は一致する。そのため、箱ひげ図において中央値を表す線が（底の）第1四分位数ないし（蓋の）第3四分位数のどちらかに寄っているのであれば、正規分布という仮定の妥当性、あるいはデータの代表性（収集した標本データが母集団の情報を反映しているのか）を再検討すべきであろう。偏っている場合には、正規分布ではなく、ポアソン分布などの適用を検討すべきかも知れない。





箱の底あるいは蓋から延びている線が「ひげ」といわれる。
ひげの長さにはいくつかの計算が提案されているのだが、代表的な方法が以下である。

1. ひげの上端は、箱の上辺 + 1.5 * 四分位範囲内の最大値
2. ひげの下端は箱の下端 - 1.5 * IQRの範囲内内の最小値


実際に計算してみよう。

```{r hei}
172.98 + (172.98 - 165.98) * 1.5
165.98 - (172.98 - 165.98) * 1.5
```

上下に伸びたひげの外にあるデータは、**外れ値**とみなされる。この場合、183.48センチより高いか、155.48 よりも低い計測値があれば、それは外れ値と判断される。このデータでは、最大値が 182.5 なので上側に外れ値はない。


### 外れ値と欠損値 {#outlier}

データには、外れ値の他、欠損値が含まれていることが多い。**欠損値**とは、ある観測対象について、何らかの理由で記録が残されていない状態を指す。データセットでは空白、あるいは NA あるいは99999として記録されていることが多い。

欠損値や外れ値をどのように扱うかは難しい問題である。欠損値がある観測対象をデータから削除してしまうのが、もっとも簡単な方法であるが、問題がないわけではない。
まず、データ数が少なくなってしまい、分析対象を代表としているのか疑わしくなってしまうことがある。さらには、欠損値が系統的に（偶然ではなく、何らかの仕組みがあって）発生している場合は、分析の結果が偏向してしまう。例えば、ある医学検査で、被験者それぞれの血圧を半年にわたって調査していたとする。このようなデータの場合、後の時期ほど欠損値が多くなる。それは、被験者の一部が検査に来なくなるためである。そのような被験者は、まったく健康であるか、逆に出かけられないほど体調が悪化していることが多い。つまり、ある特定の傾向のある被験者に集中して欠損値が多くなる。このような場合に欠損値を単純に削除してしまったデータから得られた結果は、本来の調査目的に合致しなくなるかもしれない。

欠損値を別の値で補う方法も提案されている。これを補間という。補間として平均値を代入することがよく行われるが、統計的には適切な処理とはいえない。欠損値の処理については、統計学の分野で研究がすすんでいるが、詳細は文献を参照されたい。

外れ値についても、もっとも単純な方法は削除してしまうことであるが、これも必ずしも妥当とはいえない。例えば、普通の高校で観測された身長データに 107センチという値があれば、記録ミスとして削除しても問題ないかも知れない。しかし、例えば偏差値として75という値（つまり平均値から標準偏差3個分離れた値）が申告されていた場合、57の間違いなのか、それとも事実なのか、一概には判断できないだろう。
本書では詳細は省くが、時たま大きなハズレ値を出す確率分布にコーシー分布があり、外れ値を含むデータ分析で有用となることがある。




### 水準間の比較{#levels}

**水準（レベル）**とはカテゴリデータの内訳のことである。
例えば、「性別」を表すカテゴリ変数では、一般に「女」「男」「どちらでもない」の3つの水準が考えられるだろう。カテゴリ変数では、水準ごとの特徴を確認したい場合がある。例えば、性別で年収を比較し、女の年収が不当に低いなどの現状を確認できることがある。ちなみに、カテゴリ変数の水準を分けて考えることを、**層別**するという。


例として、餌の違いが鶏の成長に与える効果の違いを考えてみよう。
ここでは「餌」がカテゴリ変数であり、その内訳（「ヒマワリの種」や「そら豆」など6種類）が水準である。

```{r chickwt_levels}
chickwts %>% ggplot(aes(x = feed, y = weight, col = feed)) + geom_boxplot()
```

餌の種類ごとに箱ひげ図が描かれているが、それぞれの箱の内部の横線が平均値を表している。乾酪(casein)が与えられた鶏と、そら豆(horse bean)を与えられた鶏では、体重にかなりの違いがあることが分かる。ここから、餌の種類によって、鶏の成長に違いが現れることが分かるだろう。



何らかの介入（この場合は餌の種類を変えること）を行い、その他の条件（鶏舎の広さなどの環境）が同じであるならば、餌の水準ごとに平均値が違うのは、餌の種類が影響していると考えるのがだろう。



## ヒストグラム {#hist}

```{r setup2, echo = FALSE}
library(tidyverse)
```
データの分布を確認するグラフとして箱ひげ図を紹介したが、他によく使われるのが**ヒストグラム**である。
身長のデータからヒストグラムを作成してみよう。

```{r hist}
df <- tibble(身長 = x,x = "A")
p <- df %>% ggplot(aes(x = 身長)) +
  geom_histogram(fill = "white", color="black")
p
```

表示されている棒（バー）の高さは、ある範囲に含まれるデータ数を表している。
一見したところ、いわゆる棒グラフ（バーチャート）のようだが、ヒストグラムではバーの並びに意味がある。この例では、横軸（X軸）の左端は100センチで、右端は180センチとなっている。つまりX軸の値は連続している。

バーチャートでは横軸が、例えば「女」と「男」、「その他」、あるいは「賛成」と「反対」などのカテゴリ変数の水準になる。それゆえ、「賛成」と「反対」それぞれのバーは左右に入れ替えても、データを確認する上で何の不都合もない。


身長データでは記載ミスに起因すると思われる外れ値が複数あるため、バーは左右に離れて密集している。例えば、約 106 センチから約 109 センチの間に6人の生徒が属しており、バーの高さは6の位置にある。バーの範囲（区間）を**ビン**(bin)と呼ぶ。



すぐに想像付くであろうが、ヒストグラムはビンの設定によって全く印象の異なるグラフとなる。ここで作図に利用しているツール(**ggplot2** パッケージ）では、デフォルトでデータを 30 個のビンに分割しようとする。


```{r bins, eval = FALSE}
## R ggplot2におけるビンの分割を確認する方法
ggplot_build(p)$data[[1]]
```

ビンを 5 個に変えてみると、どうなるだろうか。

```{r bin10}
p <- df %>% ggplot(aes(x = 身長)) +
  geom_histogram(bins = 5, fill = "white", color="black")
p
```

ビンの数を極端に減らした結果、グラフの印象も大きく変わっている。最適なビンを設定する方法が複数提案されているが（例えばスタージェスの公式）、ヒストグラムが恣意的になるのは避けられない。





ヒストグラムを使って、水準間の比較をしてみよう。先に、鶏の体重増加と餌の効果を箱ひげ図で確認した。ここではヒストグラムを使ってみよう。



```{r chick_hist}
chickwts %>% ggplot(aes(x = weight, fill=feed)) +
  geom_histogram(alpha=.3, binwidth =20)#geom_density(alpha=.5)
```

餌の種類ごとに分布が異なるのは見て取れるだろうが、重なりが多いため、餌の効果の違いを確認するのは難しいだろう。


## 散布図{#scatterplot}

箱ひげ図、ヒストグラム、バープロットは主に1つの変数を可視化するツールである。
データ分析では、二つの変数を同時に描画して、その関係を考察したいことがある。
**散布図**は、二つの変数間の関係を考察するのに多用される可視化ツールである。


```{r cars}
cars %>% ggplot(aes(speed, dist)) +
  geom_point(size = 2) + ggtitle("速度と停止距離") +
  xlab("速度（マイル）") + ylab("停止距離（フィート）")
```

図の各点は、ある乗用車のデータで、X軸にブレーキを思い切り踏む直前の速度（マイル）、Y軸に停止までに要した距離（フィート）が対応している。車を表す各点が、おおむね左下から右上に並んでいるのが見と取れる。つまり、速度が大きいほど、完全停止するまでに要する距離が大きくなるのが分かるだろう。二つのデータ間の関係をデータサイエンスでは相関と呼ぶ。





### 相関{#correlation}



散布図で車の速度と停止距離の間には何らかの関係性が確認できた。これを**相関**があると表現する。相関は、一般的には以下の式で表現される。

$$
r_{xy} = \frac{\displaystyle \sum_{i = 1}^n (x_i - \overline{x})
(y_i - \overline{y})}{\sqrt{\displaystyle \sum_{i = 1}^n 
(x_i - \overline{x})^2}\sqrt{\displaystyle \sum_{i = 1}^n 
(y_i - \overline{y})^2}}
$$

変数 $x$ の $i$ 番目の要素 $x_i$ から、$x$ の平均値 ($\overline{x}$) を引いた値は、$x$ の**偏差**である。分子は、$x$ と $y$ それぞれ $i$ 番目の要素の偏差を求めて乗じ、その合計になっている。これを**共分散**という。$x$ と $y$ それぞれの偏差の符号が一致する場合、共分散は正の値になる。逆に、それぞれの偏差の符号が異なる場合、共分散は負の値になる。符号が一致しない場合というのは、例えば、気温が高くなると、熱い食べ物（鍋）の消費量が減るなどの関係である。

共分散の大きさは、データの大きさに依存するため、二つの変数それぞれの分散の積で割った値が相関係数である。相関係数は、元データの単位に関わらず、-1から1の間の数値になる。絶対値が1に近いほど、二つの変数間には強い相関が認められる。

二つの変数の間に相関がある場合、一方を利用することで他方を予測することが可能になる。例えば、気温が高いのであれば、鍋料理の売上は低くなると予測できるだろう。これを発展させた手法が**回帰分析**であり、研究だけでなくさまざまなビジネスシーンで利用されている。回帰分析については、後述する。


### 相関と因果{#causal}

ちなみに、二つの変数間に相関が認められたとしても、それが因果であるとは限らない。**因果**とは、要するに、一方が他方の原因になっている状態のことである。
例えば、会社で社員の血圧を調べると、その年収と相関があるだろう。これは、年齢という変数を考えると説明がつく。年齢が高くなると一般に血圧は上がるが、一方で、年功序列社会では年齢が高くなると、年収も増えているのである。
つまり、血圧と年収の関係は、相関ではない。これを**疑似相関**と呼ぶ。

因果関係を立証するには、ランダム化実験などの計画的なデータ採取と分析方法が必要となる。



### Anscombe's quartet{#anscombe}


データの可視化が重要な事例として、アンスコムのデータを紹介しよう。

これは、基本統計量がまったく同じデータが、実は分布において全く異なる様相を示すデータとして知られる。

アンスコムの数値例

 I    |       | II   |      | III  |       | IV   |    
--|--|--|--|--|--|--|--
 x    | y     | x    | y    | x    | y     | x    | y   
 10.0 | 8.04  | 10.0 | 9.14 | 10.0 | 7.46  | 8.0  | 6.58 
 8.0  | 6.95  | 8.0  | 8.14 | 8.0  | 6.77  | 8.0  | 5.76 
 13.0 | 7.58  | 13.0 | 8.74 | 13.0 | 12.74 | 8.0  | 7.71  
 9.0  | 8.81  | 9.0  | 8.77 | 9.0  | 7.11  | 8.0  | 8.84  
 11.0 | 8.33  | 11.0 | 9.26 | 11.0 | 7.81  | 8.0  | 8.47  
 14.0 | 9.96  | 14.0 | 8.10 | 14.0 | 8.84  | 8.0  | 7.04  
 6.0  | 7.24  | 6.0  | 6.13 | 6.0  | 6.08  | 8.0  | 5.25  
 4.0  | 4.26  | 4.0  | 3.10 | 4.0  | 5.39  | 19.0 | 12.50 
 12.0 | 10.84 | 12.0 | 9.13 | 12.0 | 8.15  | 8.0  | 5.56  
 7.0  | 4.82  | 7.0  | 7.26 | 7.0  | 6.42  | 8.0  | 7.91  
5.0  | 5.68  | 5.0  | 4.74 | 5.0  | 5.73  | 8.0  | 6.89  



```{r anscombe2}
Anscombe <- anscombe %>%
  tibble::rowid_to_column("id") %>%
  tidyr::pivot_longer(-id,
    names_to = c("axis", "group"),
    names_sep = 1L,
    names_ptypes = list(group = integer())) %>%
  tidyr::pivot_wider(c(id, group), names_from = axis) %>%
  dplyr::select(-id) %>%
  dplyr::arrange(group)
                                                           
Anscombe 
```


データセットが4つあり、それぞれにxとyという変数がある。これらの平均と標準偏差は一致する。

```{r anscombe3}
Anscombe  %>% 
   group_by(group) %>% 
   summarise_each(list(平均=mean, 標準偏差=sd), 変数 = c(x, y))
```

しかしながら、それぞれのデータセットを散布図で描いてみると、分布がまったく異なっていることに気がつくだろう。


```{r anscombe4}
Anscombe  %>% ggplot(aes(x = x, y = y, label = group)) +
   facet_wrap(~ group, nrow = 2) +
   geom_point() +
   geom_smooth(method = "lm", formula = y ~ x, se = FALSE)

```
